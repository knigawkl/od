"""
Napisz algorytm obliczajÄ…cy entropiÄ™.
PorÃ³wnaj entropie tekstu naturalnego z entropia kryptogramu.
"""
import math

txt = "A complete sentence must have, at minimum, three things: a subject, verb, and an object. The subject is " \
      "typically a noun or a pronoun. And, if there's a subject, there's bound to be a verb because all verbs need a " \
      "subject. Finally, the object of a sentence is the thing that's being acted upon by the subject. "

crp = "Â‘Â¬Ã•Ã´0lÂ¿Ã¬ÃÃ“Ã‰Ã¹*Ã‚Ã´Â‹Â°lrsÃ½Â‘Â†Ã²+>9KÂˆÂ¢PÃ‹*ÂŒÃ‹ÃºTÃ¿ÃµÃ”Ã±aÃNÃƒjÃ¿T~Â¡Â‹bB:aÂ±Ã«ÂŠÃ–Â¿vÃ¯Â°Ã„Ã•RKI,QÂ‡VÂ¼ÂµXÃ—.qÂ®ÂÃÃ—Â§PoÂ»D&ÃÃ—ÃŠÂ‹ÂÃ™[uÂ‰Â¶Ã–Ã«Â¸N" \
      "~Â¡kÂ¤Â¼UÂµ){@Â‡Ã·*AM4Â†cÃ¦Ã¥MGÃµÂ–Â§ÃœÂˆÃ’~ÃŠÂ‘ÃŒÃ˜ÃµÃ¥(\ÂppÃ Ã¼ YÃ±RÂ¿Â•Â³Â„yZÂ¸ÃºÃ b.cZÃ©FE`DÂ¸BÂÃºÃª--ÂœÂ—Ã¤Ã²;CÃ™Â©ÃˆR1Ã–ZÂ¦Ã¾Ã§hÂ›Â¶:Â•rÃ Â˜t$9$TÃ¬5Ã˜E@Ã³Ã»pÃ¯uÂ•Âª" \
      "Â²ÃªÃ²T&rÂ—ÃšSÂ»i-bÃ­Ã„/ÃµÃ´wÃNÃ‚Â‹hÃ–Â­Â¥KFÃ–6Â¥Â€Â”Ã°NFÃ¹Â’Â¯`bÃ’ÂœÂ¸Ã¦1Y|Â¯Â¯Ã‚Ã¿_VÂŸCHoÂµÃ®z"


def calc_entropy(string):
    """Calculates the Shannon entropy of a string"""

    # get probability of chars in string
    prob = [float(string.count(c)) / len(string) for c in dict.fromkeys(list(string))]

    # calculate the entropy
    entropy = - sum([p * math.log(p) / math.log(2.0) for p in prob])

    return entropy


# print(calc_entropy(txt))
# print(calc_entropy(crp))
